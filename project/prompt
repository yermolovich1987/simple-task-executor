We are writing an application in Python that will use Open AI LLM, LangChain and Streamlit. It will be a simplified version of "gpt-engineer". It takes task on python, then trying to go through the steps of "plan implementation, design interface" and then two parallel threads of conversation - one implementing the task, second implementing the tests for that - getting compete between each other until the tests become green.
